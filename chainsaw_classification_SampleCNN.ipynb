{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fWomgC-kF5f"
   },
   "source": [
    "**Architecture **\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=12JomC2IswVbNGdE0IIvPpUk8vPjP-MBQ\"  alt=\"artchtecture\">\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uN7hQRZsDbgI"
   },
   "source": [
    "(1) Importing dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3lPxjI5BDAkX",
    "outputId": "88280284-3c51-485b-adfa-4c428507fb92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    "                         Conv1D, MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "import random\n",
    "random.seed(13)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "py5KMVLnDZsC"
   },
   "source": [
    "(2) Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/data/private/SU/bbchip13/chainsaw_classification/data/'\n",
    "chainsaw_wav_dir = base_dir+'chainsaw/'\n",
    "other_wav_dir = base_dir+'no_chainsaw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainsaw_list = [chainsaw_wav_dir+filename for filename in os.listdir(chainsaw_wav_dir) \n",
    "                 if filename.endswith('.wav')]\n",
    "chainsaw_list = sklearn.utils.shuffle(chainsaw_list)\n",
    "chainsaw_list = chainsaw_list\n",
    "chainsaw_list = chainsaw_list\n",
    "chainsaw_labels = np.ones(len(chainsaw_list))\n",
    "\n",
    "no_chainsaw_list = [other_wav_dir+filename for filename in os.listdir(other_wav_dir)\n",
    "                    if filename.endswith('.wav')]\n",
    "no_chainsaw_list = sklearn.utils.shuffle(no_chainsaw_list)\n",
    "no_chainsaw_list = no_chainsaw_list\n",
    "no_chainsaw_list = no_chainsaw_list\n",
    "no_chainsaw_labels = np.zeros(len(no_chainsaw_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavs(filenames):\n",
    "    return np.asarray([librosa.load(filename)[0] for filename in tqdm(filenames)])\n",
    "\n",
    "### If you have lack of memory, Use this\n",
    "#     wav = librosa.load(filenames[0])\n",
    "#     wavs = np.zeros( (len(filenames), wav.shape[0]) )\n",
    "#     for i, filename in enumerate(filenames):\n",
    "#         wavs[i][:] = librosa.load(filename)[:]\n",
    "#     return wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Train Data......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16596a8ddbbd41c6a8bc78cf40d0fb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2218), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load Test Data......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029e1dac15cf4dffa573a6617cb3495f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1093), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2218, 110250, 1) (2218, 1) (1093, 110250, 1) (1093, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_chainsaw, x_test_chainsaw, y_train_chainsaw, y_test_chainsaw \\\n",
    "    = train_test_split(chainsaw_list, chainsaw_labels, test_size = 0.33, random_state = 7)\n",
    "x_train_no_chainsaw, x_test_no_chainsaw, y_train_no_chainsaw, y_test_no_chainsaw \\\n",
    "    = train_test_split(no_chainsaw_list, no_chainsaw_labels, test_size = 0.33, random_state = 7)\n",
    "\n",
    "x_train_filenames = x_train_chainsaw+x_train_no_chainsaw\n",
    "y_train = np.concatenate([y_train_chainsaw, y_train_no_chainsaw])\n",
    "\n",
    "x_test_filenames = x_test_chainsaw+x_test_no_chainsaw\n",
    "y_test = np.concatenate([y_test_chainsaw, y_test_no_chainsaw])\n",
    "\n",
    "x_train_filenames, y_train = sklearn.utils.shuffle(x_train_filenames, y_train)\n",
    "x_test_filenames, y_test = sklearn.utils.shuffle(x_test_filenames, y_test)\n",
    "\n",
    "print('Load Train Data......')\n",
    "x_train = load_wavs(x_train_filenames)\n",
    "print('Load Test Data......')\n",
    "x_test = load_wavs(x_test_filenames)\n",
    "\n",
    "x_train = np.reshape(x_train, (*x_train.shape, 1))\n",
    "y_train = np.reshape(y_train, (*y_train.shape, 1))\n",
    "x_test = np.reshape(x_test, (*x_test.shape, 1))\n",
    "y_test = np.reshape(y_test, (*y_test.shape, 1))\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12cS85jvDnfS"
   },
   "source": [
    "(3) Create a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "colab_type": "code",
    "id": "fs8Heys2Dm30",
    "outputId": "bad14ede-be9c-4a2f-d052-9d9a29a5e437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 36750, 128)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36750, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 36750, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 36750, 128)        49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 36750, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 36750, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12250, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 12250, 128)        49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12250, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12250, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4083, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 4083, 256)         98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4083, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4083, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1361, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1361, 256)         196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1361, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1361, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 453, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 453, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 453, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 453, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 151, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 151, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 151, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 151, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 50, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 50, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5, 512)            393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 5, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,585,921\n",
      "Trainable params: 1,581,057\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Conv1D (kernel_size=3, filters=128, strides=3, padding='valid',\n",
    "                  kernel_initializer='he_uniform', input_shape=x_train.shape[1:]))                  \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv1D (kernel_size=3, filters=128, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv1D (kernel_size=3, filters=128, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 4\n",
    "model.add(Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 5\n",
    "model.add(Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 6\n",
    "model.add(Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 7\n",
    "model.add(Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 8\n",
    "model.add(Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 9\n",
    "model.add(Conv1D (kernel_size=3, filters=256, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 10\n",
    "model.add(Conv1D (kernel_size=3, filters=512, padding='same', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "# Layer 11\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Layer 12\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLxfqHNxDuJq"
   },
   "source": [
    "(4) Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jPB8IbZDxeJ"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUsuRj-7Dzxx"
   },
   "source": [
    "(5) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'SampleCNN_check_point/'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "model_filename = model_path+'{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", verbose=1, save_best_only=True)\n",
    "\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# cb_early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# model.fit(X, Y, validation_split=0.2, epochs=5000, batch_size=500,\n",
    "#           callbacks=[EarlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "ZUVV71K2D2tZ",
    "outputId": "7a454152-003e-4615-acd8-cfdb60ef8170",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 1552 samples, validate on 666 samples\n",
      "Epoch 1/100\n",
      "1552/1552 [==============================] - 33s 21ms/step - loss: 0.3130 - acc: 0.8769 - val_loss: 1.3046 - val_acc: 0.7117\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.30455, saving model to SampleCNN_check_point/01-1.3046.hdf5\n",
      "Epoch 2/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.2485 - acc: 0.9240 - val_loss: 0.1628 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.30455 to 0.16281, saving model to SampleCNN_check_point/02-0.1628.hdf5\n",
      "Epoch 3/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.1486 - acc: 0.9510 - val_loss: 0.0863 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16281 to 0.08627, saving model to SampleCNN_check_point/03-0.0863.hdf5\n",
      "Epoch 4/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.1195 - acc: 0.9575 - val_loss: 0.0983 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08627\n",
      "Epoch 5/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.1291 - acc: 0.9555 - val_loss: 0.1160 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08627\n",
      "Epoch 6/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0836 - acc: 0.9704 - val_loss: 0.1082 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08627\n",
      "Epoch 7/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0850 - acc: 0.9736 - val_loss: 0.1233 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08627\n",
      "Epoch 8/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0919 - acc: 0.9704 - val_loss: 0.2092 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08627\n",
      "Epoch 9/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0725 - acc: 0.9723 - val_loss: 0.0823 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08627 to 0.08227, saving model to SampleCNN_check_point/09-0.0823.hdf5\n",
      "Epoch 10/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0782 - acc: 0.9678 - val_loss: 0.1917 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08227\n",
      "Epoch 11/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0715 - acc: 0.9729 - val_loss: 0.0904 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.08227\n",
      "Epoch 12/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0880 - acc: 0.9678 - val_loss: 0.1009 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.08227\n",
      "Epoch 13/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0785 - acc: 0.9729 - val_loss: 0.0628 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08227 to 0.06284, saving model to SampleCNN_check_point/13-0.0628.hdf5\n",
      "Epoch 14/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0641 - acc: 0.9755 - val_loss: 0.0870 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06284\n",
      "Epoch 15/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0472 - acc: 0.9845 - val_loss: 0.3370 - val_acc: 0.8964\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06284\n",
      "Epoch 16/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0494 - acc: 0.9807 - val_loss: 0.0622 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06284 to 0.06216, saving model to SampleCNN_check_point/16-0.0622.hdf5\n",
      "Epoch 17/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0452 - acc: 0.9852 - val_loss: 0.0653 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06216\n",
      "Epoch 18/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0543 - acc: 0.9794 - val_loss: 0.1566 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.06216\n",
      "Epoch 19/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0555 - acc: 0.9794 - val_loss: 0.0862 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.06216\n",
      "Epoch 20/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0428 - acc: 0.9845 - val_loss: 0.1955 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.06216\n",
      "Epoch 21/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0332 - acc: 0.9878 - val_loss: 0.0710 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06216\n",
      "Epoch 22/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0404 - acc: 0.9865 - val_loss: 0.2231 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06216\n",
      "Epoch 23/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0382 - acc: 0.9897 - val_loss: 0.1296 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06216\n",
      "Epoch 24/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0408 - acc: 0.9878 - val_loss: 0.0945 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.06216\n",
      "Epoch 25/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0443 - acc: 0.9852 - val_loss: 0.0864 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06216\n",
      "Epoch 26/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0301 - acc: 0.9903 - val_loss: 0.0851 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06216\n",
      "Epoch 27/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0313 - acc: 0.9910 - val_loss: 0.0863 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06216\n",
      "Epoch 28/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0404 - acc: 0.9865 - val_loss: 0.0717 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.06216\n",
      "Epoch 29/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0234 - acc: 0.9923 - val_loss: 0.0880 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06216\n",
      "Epoch 30/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0323 - acc: 0.9858 - val_loss: 0.0688 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06216\n",
      "Epoch 31/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0246 - acc: 0.9903 - val_loss: 0.0975 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06216\n",
      "Epoch 32/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0176 - acc: 0.9961 - val_loss: 0.0473 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.06216 to 0.04730, saving model to SampleCNN_check_point/32-0.0473.hdf5\n",
      "Epoch 33/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0213 - acc: 0.9929 - val_loss: 0.1427 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04730\n",
      "Epoch 34/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0927 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04730\n",
      "Epoch 35/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0830 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04730\n",
      "Epoch 36/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0260 - acc: 0.9923 - val_loss: 0.1180 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04730\n",
      "Epoch 37/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0193 - acc: 0.9936 - val_loss: 0.0786 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04730\n",
      "Epoch 38/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0233 - acc: 0.9923 - val_loss: 0.0542 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04730\n",
      "Epoch 39/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0534 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04730\n",
      "Epoch 40/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0036 - acc: 0.9994 - val_loss: 0.0559 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04730\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0157 - acc: 0.9929 - val_loss: 0.1029 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04730\n",
      "Epoch 42/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0163 - acc: 0.9929 - val_loss: 0.0773 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04730\n",
      "Epoch 43/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0125 - acc: 0.9948 - val_loss: 0.0548 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04730\n",
      "Epoch 44/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0182 - acc: 0.9948 - val_loss: 0.1045 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04730\n",
      "Epoch 45/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0281 - acc: 0.9897 - val_loss: 0.0499 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04730\n",
      "Epoch 46/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0272 - acc: 0.9890 - val_loss: 0.0679 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04730\n",
      "Epoch 47/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0173 - acc: 0.9942 - val_loss: 0.0697 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04730\n",
      "Epoch 48/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.0640 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04730\n",
      "Epoch 49/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0613 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04730\n",
      "Epoch 50/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0835 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04730\n",
      "Epoch 51/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0183 - acc: 0.9955 - val_loss: 0.1096 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04730\n",
      "Epoch 52/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.0800 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04730\n",
      "Epoch 53/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0442 - acc: 0.9865 - val_loss: 0.0678 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04730\n",
      "Epoch 54/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0162 - acc: 0.9955 - val_loss: 0.0743 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04730\n",
      "Epoch 55/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0255 - acc: 0.9903 - val_loss: 0.0737 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04730\n",
      "Epoch 56/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0110 - acc: 0.9981 - val_loss: 0.0640 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.04730\n",
      "Epoch 57/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0073 - acc: 0.9968 - val_loss: 0.0649 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04730\n",
      "Epoch 58/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0082 - acc: 0.9961 - val_loss: 0.0614 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04730\n",
      "Epoch 59/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0755 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04730\n",
      "Epoch 60/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0036 - acc: 0.9994 - val_loss: 0.0727 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04730\n",
      "Epoch 61/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0772 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04730\n",
      "Epoch 62/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.1443 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04730\n",
      "Epoch 63/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0076 - acc: 0.9968 - val_loss: 0.0652 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04730\n",
      "Epoch 64/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0647 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04730\n",
      "Epoch 65/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04730\n",
      "Epoch 66/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0989 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04730\n",
      "Epoch 67/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0827 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04730\n",
      "Epoch 68/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0938 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04730\n",
      "Epoch 69/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0817 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04730\n",
      "Epoch 70/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.1041 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04730\n",
      "Epoch 71/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0877 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04730\n",
      "Epoch 72/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0817 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04730\n",
      "Epoch 73/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.0627 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04730\n",
      "Epoch 74/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.1209 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.04730\n",
      "Epoch 75/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0132 - acc: 0.9968 - val_loss: 0.0819 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04730\n",
      "Epoch 76/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0780 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04730\n",
      "Epoch 77/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0062 - acc: 0.9968 - val_loss: 0.0723 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04730\n",
      "Epoch 78/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0697 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04730\n",
      "Epoch 79/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1053 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04730\n",
      "Epoch 80/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0883 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04730\n",
      "Epoch 81/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.1522 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04730\n",
      "Epoch 82/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0089 - acc: 0.9961 - val_loss: 0.1229 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04730\n",
      "Epoch 83/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.1537 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04730\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1079 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04730\n",
      "Epoch 85/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 8.4033e-04 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04730\n",
      "Epoch 86/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04730\n",
      "Epoch 87/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04730\n",
      "Epoch 88/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04730\n",
      "Epoch 89/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0614 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04730\n",
      "Epoch 90/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0808 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04730\n",
      "Epoch 91/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0013 - acc: 0.9994 - val_loss: 0.0718 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04730\n",
      "Epoch 92/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0780 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04730\n",
      "Epoch 93/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.1420 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04730\n",
      "Epoch 94/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0074 - acc: 0.9968 - val_loss: 0.0672 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04730\n",
      "Epoch 95/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0646 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04730\n",
      "Epoch 96/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0632 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04730\n",
      "Epoch 97/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 8.1375e-04 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04730\n",
      "Epoch 98/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0679 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04730\n",
      "Epoch 99/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0900 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04730\n",
      "Epoch 100/100\n",
      "1552/1552 [==============================] - 27s 17ms/step - loss: 0.0063 - acc: 0.9961 - val_loss: 0.0940 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04730\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.3, \n",
    "                 shuffle=True, callbacks = [checkpointer])\n",
    "\n",
    "#   model.fit_tfrecord(epochs=100,\n",
    "#                      initial_epoch=initial_epoch,\n",
    "#                      steps_per_epoch=train_steps,\n",
    "#                      validation_steps=val_steps,\n",
    "#                      callbacks=[tensor_board, early_stopping,\n",
    "#                                 checkpointer, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_model(model_path+'32-0.0473.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DefsBoWAFKdi",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 7s 6ms/step\n",
      "Loss: 0.07264508801526906 Accuracy: 0.9780420860018298\n"
     ]
    }
   ],
   "source": [
    "[loss, accuracy] = model.evaluate(x_test, y_test)\n",
    "print('Loss:', loss, 'Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9829059829059829\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "test_f1_score = f1_score(y_test, pred > 0.5)\n",
    "print('F1 Score:', test_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.15 s ± 11.1 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 -r 5 model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "brains_on_beats_model_test",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

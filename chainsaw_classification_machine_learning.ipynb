{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/'\n",
    "train_dir = base_dir+'train/'\n",
    "val_dir = base_dir+'val/'\n",
    "test_dir = base_dir+'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavs(filenames):\n",
    "    return np.asarray([librosa.load(filename)[0] for filename in tqdm(filenames)])\n",
    "\n",
    "### If you have lack of memory, Use this\n",
    "#     wav = librosa.load(filenames[0])\n",
    "#     wavs = np.zeros( (len(filenames), wav.shape[0]) )\n",
    "#     for i, filename in enumerate(filenames):\n",
    "#         wavs[i][:] = librosa.load(filename)[:]\n",
    "#     return wavs\n",
    "    \n",
    "def find_y_by_filename(filename, y_dict):\n",
    "    basename = os.path.basename(filename)\n",
    "    y = y_dict[basename]\n",
    "    return y\n",
    "\n",
    "def make_y_by_filenames(filenames, y_dict):\n",
    "    return np.asarray([find_y_by_filename(filename, y_dict) \n",
    "                           for filename in filenames])\n",
    "\n",
    "def make_xy_data(filenames, y_dict):\n",
    "    x_train = load_wavs(filenames)\n",
    "    y_train = make_y_by_filenames(filenames, y_dict)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make Y data\n",
    "annotations_filename = 'data_annotations.csv'\n",
    "df = pd.read_csv(annotations_filename)\n",
    "y_dict = {filename:int(label) for _, filename, label, _ in df.itertuples()}\n",
    "# y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make train data.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2257/2257 [10:22<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 110250) (2257,)\n"
     ]
    }
   ],
   "source": [
    "print('Make train data.......')\n",
    "x_train_wav_filenames = [train_dir+filename for filename in os.listdir(train_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "x_val_wav_filenames = [val_dir+filename for filename in os.listdir(val_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "x_train_wav_filenames += x_val_wav_filenames\n",
    "x_train_wavs, y_train = make_xy_data(x_train_wav_filenames, y_dict)\n",
    "\n",
    "print(x_train_wavs.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Make test data.......')\n",
    "x_test_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "x_test_wavs, y_test = make_xy_data(x_test_wav_filenames, y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wav):\n",
    "    wav = sklearn.preprocessing.maxabs_scale(wav)\n",
    "    wav_mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13)\n",
    "    wav_mfcc_std = StandardScaler().fit_transform(wav_mfcc)\n",
    "    wav_mfcc_std_mean = wav_mfcc_std.mean(axis=1)\n",
    "\n",
    "    features = np.concatenate([wav_mfcc_std_mean])\n",
    "    return features\n",
    "\n",
    "def train(x_train_wavs, y_train):\n",
    "    x_train = np.apply_along_axis(preprocess, 1, x_train_wavs)\n",
    "\n",
    "    logreg = linear_model.LogisticRegression(penalty='l2', C=0.5)\n",
    "    logreg.fit(x_train, y_train)\n",
    "    print('Logistic Regression Score:', logreg.score(x_train, y_train))\n",
    "    joblib.dump(logreg, 'logreg_chainsaw.pkl')\n",
    "    \n",
    "    linear_svc = LinearSVC()\n",
    "    linear_svc.fit(x_train, y_train)\n",
    "    print('Linear SVM Score:', linear_svc.score(x_train, y_train))\n",
    "    joblib.dump(linear_svc, 'linear_svc_chainsaw.pkl') \n",
    "\n",
    "    kernel_svc = SVC()\n",
    "    kernel_svc.fit(x_train, y_train)\n",
    "    print('Kernel SVM Score:', kernel_svc.score(x_train, y_train))\n",
    "    joblib.dump(kernel_svc, 'kernel_svc_chainsaw.pkl')\n",
    "\n",
    "    print()\n",
    "\n",
    "def test(x_test_wavs, y_test):\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "\n",
    "    clf = joblib.load('logreg_chainsaw.pkl')\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Logistic Regression Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Logistic Regression F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()\n",
    "    \n",
    "    clf = joblib.load('linear_svc_chainsaw.pkl')\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Linear SVM Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Linear SVM F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()\n",
    "    \n",
    "    clf = joblib.load('kernel_svc_chainsaw.pkl')\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Kernel SVM Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Kernel SVM F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.9308817013735047\n",
      "Linear SVM Score: 0.9308817013735047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM Score: 0.9481612760301285\n",
      "\n",
      "169 µs ± 13.7 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.9354838709677419\n",
      "Logistic Regression F1 Score: 0.9470404984423676\n",
      "\n",
      "340 µs ± 138 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.9307400379506642\n",
      "Linear SVM F1 Score: 0.9432789432789432\n",
      "\n",
      "15.6 ms ± 1.58 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.9516129032258065\n",
      "Kernel SVM F1 Score: 0.9606784888203548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(x_train_wavs, y_train)\n",
    "test(x_test_wavs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1cec8504a9421087f6cd61727e87e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.6 µs ± 20.5 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "The slowest run took 4.31 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "130 µs ± 63.3 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 Score: 0.0\n",
      "\n",
      "682 µs ± 32.7 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700c8205118f4424955e5c2a96704364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.1 µs ± 4.82 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "78.8 µs ± 30.3 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 Score: 0.0\n",
      "\n",
      "680 µs ± 138 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c7982490bf4aed89aba48d6f40cbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.9 µs ± 15.9 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "183 µs ± 57.3 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 Score: 0.0\n",
      "\n",
      "838 µs ± 121 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'wind/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'rain/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'engine/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wav):\n",
    "    wav = sklearn.preprocessing.maxabs_scale(wav)\n",
    "    wav_mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13)\n",
    "#     wav_mfcc_std = StandardScaler().fit_transform(wav_mfcc)\n",
    "    wav_mfcc_std_mean = wav_mfcc.mean(axis=1)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(wav, n_mels=128)\n",
    "    log_S = librosa.amplitude_to_db(S)    \n",
    "#     log_S_std = StandardScaler().fit_transform(log_S)\n",
    "    log_S_std_mean = log_S.mean(axis=1)\n",
    "    \n",
    "    features = np.concatenate([wav_mfcc_std_mean, log_S_std_mean])\n",
    "    return features\n",
    "\n",
    "def train(x_train_wavs, y_train):\n",
    "    x_train = np.apply_along_axis(preprocess, 1, x_train_wavs)\n",
    "\n",
    "    logreg = linear_model.LogisticRegression(C=0.01)\n",
    "    logreg.fit(x_train, y_train)\n",
    "    print('Logistic Regression Score:', logreg.score(x_train, y_train))\n",
    "    joblib.dump(logreg, 'logreg_chainsaw.pkl')\n",
    "    \n",
    "    linear_svc = LinearSVC()\n",
    "    linear_svc.fit(x_train, y_train)\n",
    "    print('Linear SVM Score:', linear_svc.score(x_train, y_train))\n",
    "    joblib.dump(linear_svc, 'linear_svc_chainsaw.pkl') \n",
    "\n",
    "    kernel_svc = SVC()\n",
    "    kernel_svc.fit(x_train, y_train)\n",
    "    print('Kernel SVM Score:', kernel_svc.score(x_train, y_train))\n",
    "    joblib.dump(kernel_svc, 'kernel_svc_chainsaw.pkl')\n",
    "\n",
    "    print()\n",
    "\n",
    "def test(x_test_wavs, y_test):\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "\n",
    "    clf = joblib.load('logreg_chainsaw.pkl')\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Logistic Regression Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Logistic Regression F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()\n",
    "    \n",
    "    clf = joblib.load('linear_svc_chainsaw.pkl')\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Linear SVM Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Linear SVM F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()\n",
    "    \n",
    "    clf = joblib.load('kernel_svc_chainsaw.pkl')\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Kernel SVM Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Kernel SVM F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.9654408506867523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Score: 0.9534780682321666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM Score: 1.0\n",
      "\n",
      "353 µs ± 65.7 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.969639468690702\n",
      "Logistic Regression F1 Score: 0.9750390015600624\n",
      "\n",
      "The slowest run took 5.70 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "787 µs ± 376 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.9421252371916509\n",
      "Linear SVM F1 Score: 0.9528957528957529\n",
      "\n",
      "725 ms ± 34.3 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.6015180265654649\n",
      "Kernel SVM F1 Score: 0.7511848341232228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(x_train_wavs, y_train)\n",
    "test(x_test_wavs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d393b4e1fe4798ac58ffeedb801c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.3 µs ± 14.7 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "75.1 µs ± 17.3 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 Score: 0.0\n",
      "\n",
      "25.8 ms ± 521 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d954c8c4e95f47caac061edbe763f736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.7 µs ± 8.03 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "The slowest run took 7.73 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "155 µs ± 147 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 Score: 0.0\n",
      "\n",
      "25.7 ms ± 3.22 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984fa4ad039e43a8aa3e4b56bef7a88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.7 µs ± 6.27 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "76.4 µs ± 12.5 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Linear SVM Accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 Score: 0.0\n",
      "\n",
      "27.4 ms ± 4.04 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'wind/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'rain/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'engine/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141,)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(x_temp_wavs[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

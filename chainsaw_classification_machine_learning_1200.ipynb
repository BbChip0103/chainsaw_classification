{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/'\n",
    "train_dir = base_dir+'train/'\n",
    "val_dir = base_dir+'val/'\n",
    "test_dir = base_dir+'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavs(filenames):\n",
    "    return np.asarray([librosa.load(filename)[0] for filename in tqdm(filenames)])\n",
    "\n",
    "### If you have lack of memory, Use this\n",
    "#     wav = librosa.load(filenames[0])\n",
    "#     wavs = np.zeros( (len(filenames), wav.shape[0]) )\n",
    "#     for i, filename in enumerate(filenames):\n",
    "#         wavs[i][:] = librosa.load(filename)[:]\n",
    "#     return wavs\n",
    "    \n",
    "def find_y_by_filename(filename, y_dict):\n",
    "    basename = os.path.basename(filename)\n",
    "    y = y_dict[basename]\n",
    "    return y\n",
    "\n",
    "def make_y_by_filenames(filenames, y_dict):\n",
    "    return np.asarray([find_y_by_filename(filename, y_dict) \n",
    "                           for filename in filenames])\n",
    "\n",
    "def make_xy_data(filenames, y_dict):\n",
    "    x_train = load_wavs(filenames)\n",
    "    y_train = make_y_by_filenames(filenames, y_dict)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make Y data\n",
    "annotations_filename = '1200_data_annotations.csv'\n",
    "df = pd.read_csv(annotations_filename)\n",
    "y_dict = {filename:int(label) for _, filename, label, _ in df.itertuples()}\n",
    "# y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make train data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdf3b68ade247b1b69570c991f2981c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1856, 110250) (1856,)\n"
     ]
    }
   ],
   "source": [
    "print('Make train data.......')\n",
    "x_train_wav_filenames = [train_dir+filename for filename in os.listdir(train_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "x_val_wav_filenames = [val_dir+filename for filename in os.listdir(val_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "x_train_wav_filenames += x_val_wav_filenames\n",
    "x_train_wavs, y_train = make_xy_data(x_train_wav_filenames, y_dict)\n",
    "\n",
    "print(x_train_wavs.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee010f981ce48feaa784744198c59a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=884), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Make test data.......')\n",
    "x_test_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "x_test_wavs, y_test = make_xy_data(x_test_wav_filenames, y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wav):\n",
    "    wav = sklearn.preprocessing.maxabs_scale(wav)\n",
    "    wav_mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13)\n",
    "    wav_mfcc_std = StandardScaler().fit_transform(wav_mfcc)\n",
    "    wav_mfcc_std_mean = wav_mfcc_std.mean(axis=1)\n",
    "\n",
    "    features = np.concatenate([wav_mfcc_std_mean])\n",
    "    return features\n",
    "\n",
    "def train(x_train_wavs, y_train):\n",
    "    x_train = np.apply_along_axis(preprocess, 1, x_train_wavs)\n",
    "\n",
    "    logreg = linear_model.LogisticRegression(penalty='l2', C=0.5)\n",
    "    logreg.fit(x_train, y_train)\n",
    "    print('Logistic Regression Score:', logreg.score(x_train, y_train))\n",
    "    joblib.dump(logreg, '1200_logreg_chainsaw_mfcc_13.pkl')\n",
    "    \n",
    "    kernel_svc = SVC()\n",
    "    kernel_svc.fit(x_train, y_train)\n",
    "    print('Kernel SVM Score:', kernel_svc.score(x_train, y_train))\n",
    "    joblib.dump(kernel_svc, '1200_kernel_svc_chainsaw_mfcc_13.pkl')\n",
    "\n",
    "    print()\n",
    "\n",
    "def test(x_test_wavs, y_test):\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "\n",
    "    clf = joblib.load('1200_logreg_chainsaw_mfcc_13.pkl')\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Logistic Regression Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Logistic Regression F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()\n",
    "    \n",
    "    clf = joblib.load('1200_kernel_svc_chainsaw_mfcc_13.pkl')\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Kernel SVM Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Kernel SVM F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.9116379310344828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM Score: 0.9423491379310345\n",
      "\n",
      "The slowest run took 4.39 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "200 µs ± 120 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.9321266968325792\n",
      "Logistic Regression F1 Score: 0.933920704845815\n",
      "\n",
      "10.7 ms ± 242 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.9457013574660633\n",
      "Kernel SVM F1 Score: 0.947939262472885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(x_train_wavs, y_train)\n",
    "test(x_test_wavs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72c5638f404461e9212428a5cb0ec32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The slowest run took 4.79 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "82.5 µs ± 45.4 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "536 µs ± 9.56 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8aa7e2170214ed4aeb4480cff903174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "45 µs ± 4.75 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "544 µs ± 17.7 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445e30595339498a86aa9270ea5f8340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "46.5 µs ± 6.21 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "557 µs ± 33.9 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'wind/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'rain/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'engine/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wav):\n",
    "    wav = sklearn.preprocessing.maxabs_scale(wav)\n",
    "    wav_mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13)\n",
    "#     wav_mfcc_std = StandardScaler().fit_transform(wav_mfcc)\n",
    "    wav_mfcc_std_mean = wav_mfcc.mean(axis=1)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(wav, n_mels=128)\n",
    "    log_S = librosa.amplitude_to_db(S) \n",
    "#     log_S_std = StandardScaler().fit_transform(log_S)\n",
    "    log_S_std_mean = log_S.mean(axis=1)\n",
    "    \n",
    "    features = np.concatenate([wav_mfcc_std_mean, log_S_std_mean])\n",
    "    return features\n",
    "\n",
    "def train(x_train_wavs, y_train):\n",
    "    x_train = np.apply_along_axis(preprocess, 1, x_train_wavs)\n",
    "\n",
    "    logreg = linear_model.LogisticRegression(C=0.5)\n",
    "    logreg.fit(x_train, y_train)\n",
    "    print('Logistic Regression Score:', logreg.score(x_train, y_train))\n",
    "    joblib.dump(logreg, '1200_logreg_chainsaw_mfcc_logmel_C0.5.pkl')\n",
    "    \n",
    "    print()\n",
    "\n",
    "def test(x_test_wavs, y_test):\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "\n",
    "    clf = joblib.load('1200_logreg_chainsaw_mfcc_logmel_C0.5.pkl')\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Logistic Regression Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Logistic Regression F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.9665948275862069\n",
      "\n",
      "330 µs ± 69.4 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.9423076923076923\n",
      "Logistic Regression F1 Score: 0.9437706725468578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(x_train_wavs, y_train)\n",
    "test(x_test_wavs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e10f8209f24582bb7d806fa4b573d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "70.9 µs ± 31.4 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6e3543f8f4417db7c2cb1587dcef07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "55.9 µs ± 14.1 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1370dedcd0d42dbadd3de12a282b692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "53.6 µs ± 6.98 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'wind/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'rain/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'engine/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wav):\n",
    "    wav = sklearn.preprocessing.maxabs_scale(wav)\n",
    "    wav_mfcc = librosa.feature.mfcc(y=wav, n_mfcc=13)\n",
    "    wav_mfcc_std = StandardScaler().fit_transform(wav_mfcc)\n",
    "    wav_mfcc_std_mean = wav_mfcc_std.mean(axis=1)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(wav, n_mels=128)\n",
    "    log_S = librosa.amplitude_to_db(S) \n",
    "    log_S_std = StandardScaler().fit_transform(log_S)\n",
    "    log_S_std_mean = log_S_std.mean(axis=1)\n",
    "    \n",
    "    features = np.concatenate([wav_mfcc_std_mean, log_S_std_mean])\n",
    "    return features\n",
    "\n",
    "def train(x_train_wavs, y_train):\n",
    "    x_train = np.apply_along_axis(preprocess, 1, x_train_wavs)\n",
    "\n",
    "    logreg = linear_model.LogisticRegression(C=0.1)\n",
    "    logreg.fit(x_train, y_train)\n",
    "    print('Logistic Regression Score:', logreg.score(x_train, y_train))\n",
    "    joblib.dump(logreg, '1200_logreg_chainsaw_mfcc_logmel_C0.1_std.pkl')\n",
    "     \n",
    "    kernel_svc = SVC()\n",
    "    kernel_svc.fit(x_train, y_train)\n",
    "    print('Kernel SVM Score:', kernel_svc.score(x_train, y_train))\n",
    "    joblib.dump(kernel_svc, '1200_kernel_svc_chainsaw_mfcc_13_std.pkl')\n",
    "\n",
    "    print()\n",
    "\n",
    "def test(x_test_wavs, y_test):\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "\n",
    "    clf = joblib.load('1200_logreg_chainsaw_mfcc_logmel_C0.1_std.pkl')\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Logistic Regression Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Logistic Regression F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()\n",
    "    \n",
    "    clf = joblib.load('1200_kernel_svc_chainsaw_mfcc_13_std.pkl')\n",
    "    x_test = np.apply_along_axis(preprocess, 1, x_test_wavs)\n",
    "    %timeit -n 10 -r 10 clf.predict(x_test)\n",
    "    y_test_estimated = clf.predict(x_test)\n",
    "    print('Kernel SVM Accuracy:', accuracy_score(y_test_estimated, y_test))\n",
    "    print('Kernel SVM F1 Score:', f1_score(y_test, y_test_estimated))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331 µs ± 85.5 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.9615384615384616\n",
      "Logistic Regression F1 Score: 0.9626373626373628\n",
      "\n",
      "99.4 ms ± 7.55 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.9660633484162896\n",
      "Kernel SVM F1 Score: 0.9672489082969432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(x_train_wavs, y_train)\n",
    "test(x_test_wavs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1d7eb6912a46f78a55afd645ca89d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "71.8 µs ± 39.2 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "3.93 ms ± 148 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea6657b4bc64480bcf699e0b97c6c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "56.2 µs ± 12.1 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "5.39 ms ± 1.69 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n",
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05527981ade04e76b01b7db17663141c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "118 µs ± 19.8 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "4.18 ms ± 598 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'wind/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'rain/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)\n",
    "\n",
    "base_dir = '../ESC-50-master/split_wav/'\n",
    "test_dir = base_dir+'engine/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [test_dir+filename for filename in os.listdir(test_dir)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make test data.......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24705237ae8f484cb61463ee94ffb76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "65.4 µs ± 17.3 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Logistic Regression Accuracy: 1.0\n",
      "Logistic Regression F1 Score: 0.0\n",
      "\n",
      "5.8 ms ± 210 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n",
      "Kernel SVM Accuracy: 0.9833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bbchip\\desktop\\project\\chainsaw_classfication\\vir_chainsaw\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "presentation_audio_path = '../presentation_audio/'\n",
    "\n",
    "print('Make test data.......')\n",
    "x_temp_wav_filenames = [presentation_audio_path+filename for filename in os.listdir(presentation_audio_path)\n",
    "                            if filename.endswith('.wav')]\n",
    "# x_temp_wavs, y_temp = make_xy_data(x_test_wav_filenames, y_dict)\n",
    "\n",
    "x_temp_wavs = load_wavs(x_temp_wav_filenames)\n",
    "y_temp = np.zeros(x_temp_wavs.shape[0])\n",
    "\n",
    "test(x_temp_wavs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
